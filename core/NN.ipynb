{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db3612a",
   "metadata": {},
   "source": [
    "# Obtained_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce088793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad86276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshuman Raj\\AppData\\Local\\Temp\\ipykernel_23584\\192256860.py:3: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  item_data=pd.read_csv(\"Final_Anime_Dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user_data=pd.read_csv(\"Final_User_Dataset.csv\")\n",
    "item_data=pd.read_csv(\"Final_Anime_Dataset.csv\")\n",
    "user_input=pd.read_csv(\"User_input.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f25c55f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[user_data.columns[21]].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20eed514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([np.int64(347), 'troublesome4u', 'Male', np.float64(8.64),\n",
       "       np.float64(167.0), np.float64(8.84), np.float64(8.83),\n",
       "       np.float64(7.93), np.float64(9.56), np.float64(7.06),\n",
       "       np.float64(8.1), np.float64(8.67), np.float64(8.0),\n",
       "       np.float64(6.8), np.float64(8.47), np.float64(7.17),\n",
       "       np.float64(7.53), np.float64(6.47), np.float64(8.54),\n",
       "       np.float64(6.83), np.float64(8.57), np.float64(8.32),\n",
       "       np.float64(7.87), np.float64(9.0), np.float64(8.69),\n",
       "       np.float64(10.0), np.int64(47), 'Gen_X', np.int64(0), np.int64(1)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.iloc[21, :].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4627a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_data[\"avg_Romance\"] = pd.to_numeric(user_data[\"avg_Romance\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "066899aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class GenreRatingTypeConverter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that converts all columns with a specific prefix to numeric data types,\n",
    "    handling non-numeric values by converting them to NaN.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    column_prefix : str, default='avg_'\n",
    "        Prefix used to identify columns for conversion\n",
    "    errors : str, default='coerce'\n",
    "        How to handle errors in conversion:\n",
    "        - 'ignore': leave invalid values as is\n",
    "        - 'raise': raise an exception\n",
    "        - 'coerce': convert invalid values to NaN\n",
    "    downcast : str or None, default=None\n",
    "        Type to downcast to if possible ('integer', 'signed', 'unsigned', 'float')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, column_prefix='avg_', errors='coerce', downcast=None):\n",
    "        self.column_prefix = column_prefix\n",
    "        self.errors = errors\n",
    "        self.downcast = downcast\n",
    "        self.columns_converted_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Identify columns to convert based on prefix.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame\n",
    "        y : array-like, default=None\n",
    "            Not used, present for API consistency\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        # Identify columns starting with the specified prefix\n",
    "        self.columns_converted_ = [col for col in X.columns if col.startswith(self.column_prefix)]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Convert identified columns to numeric types.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame to transform\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            Transformed DataFrame with numeric columns\n",
    "        \"\"\"\n",
    "        X_result = X.copy()\n",
    "        \n",
    "        for column in self.columns_converted_:\n",
    "            X_result[column] = pd.to_numeric(X_result[column], \n",
    "                                             errors=self.errors, \n",
    "                                             downcast=self.downcast)\n",
    "        \n",
    "        return X_result\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"\n",
    "        Get output feature names.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_features : array-like of str or None, default=None\n",
    "            Input features\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of converted column names\n",
    "        \"\"\"\n",
    "        return self.columns_converted_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f90724c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_Action: float64\n",
      "avg_Adventure: float64\n",
      "avg_Avant Garde: float64\n",
      "avg_Award Winning: float64\n",
      "avg_Boys Love: float64\n",
      "avg_Comedy: float64\n",
      "avg_Drama: float64\n",
      "avg_Ecchi: float64\n",
      "avg_Erotica: float64\n",
      "avg_Fantasy: float64\n",
      "avg_Girls Love: float64\n",
      "avg_Gourmet: float64\n",
      "avg_Hentai: float64\n",
      "avg_Horror: float64\n",
      "avg_Mystery: float64\n",
      "avg_Romance: float64\n",
      "avg_Sci-Fi: float64\n",
      "avg_Slice of Life: float64\n",
      "avg_Sports: float64\n",
      "avg_Supernatural: float64\n",
      "avg_Suspense: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize the transformer\n",
    "genre_converter = GenreRatingTypeConverter(column_prefix='avg_', errors='coerce')\n",
    "\n",
    "# Apply the transformation\n",
    "user_data = genre_converter.fit_transform(user_data)\n",
    "\n",
    "# Check the data types of converted columns\n",
    "for col in genre_converter.columns_converted_:\n",
    "    print(f\"{col}: {user_data[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "278053da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"avg_Romance\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e309d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of avg_Mystery: 1.0 to 10.0\n"
     ]
    }
   ],
   "source": [
    "min_value = user_data['avg_Mystery'].min()\n",
    "max_value = user_data['avg_Mystery'].max()\n",
    "print(f\"Range of avg_Mystery: {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77ed4ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"avg_Mystery\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a528533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19848, 1571)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bbd5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Gender', 'Mean Score', 'Completed',\n",
       "       'avg_Action', 'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ede8c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>Premiered</th>\n",
       "      <th>...</th>\n",
       "      <th>Studio_pH Studio, D &amp; D Pictures</th>\n",
       "      <th>Studio_pH Studio, Noovo</th>\n",
       "      <th>Studio_production doA</th>\n",
       "      <th>Studio_studio MOTHER</th>\n",
       "      <th>Studio_studio YOG</th>\n",
       "      <th>Studio_trenova</th>\n",
       "      <th>Studio_ufotable</th>\n",
       "      <th>Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive</th>\n",
       "      <th>Studio_ufotable, feel., Studio Flag</th>\n",
       "      <th>Release_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9517</th>\n",
       "      <td>30711</td>\n",
       "      <td>Code Geass: Boukoku no Akito 5 - Itoshiki Mono...</td>\n",
       "      <td>Code Geass: Akito the Exiled - To Beloved Ones</td>\n",
       "      <td>コードギアス 亡国のアキト 最終章 「愛シキモノタチへ」</td>\n",
       "      <td>7.13</td>\n",
       "      <td>Action</td>\n",
       "      <td>The Ark Fleet has been destroyed, and a signif...</td>\n",
       "      <td>1</td>\n",
       "      <td>Feb 6, 2016</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                               Name  \\\n",
       "9517     30711  Code Geass: Boukoku no Akito 5 - Itoshiki Mono...   \n",
       "\n",
       "                                        English name  \\\n",
       "9517  Code Geass: Akito the Exiled - To Beloved Ones   \n",
       "\n",
       "                        Other name  Score  Genres  \\\n",
       "9517  コードギアス 亡国のアキト 最終章 「愛シキモノタチへ」   7.13  Action   \n",
       "\n",
       "                                               Synopsis  Episodes  \\\n",
       "9517  The Ark Fleet has been destroyed, and a signif...         1   \n",
       "\n",
       "            Aired Premiered  ... Studio_pH Studio, D & D Pictures  \\\n",
       "9517  Feb 6, 2016   UNKNOWN  ...                                0   \n",
       "\n",
       "     Studio_pH Studio, Noovo Studio_production doA Studio_studio MOTHER  \\\n",
       "9517                       0                     0                    0   \n",
       "\n",
       "     Studio_studio YOG Studio_trenova Studio_ufotable  \\\n",
       "9517                 0              0               0   \n",
       "\n",
       "      Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
       "9517                                                  0                                          \n",
       "\n",
       "      Studio_ufotable, feel., Studio Flag  Release_Year  \n",
       "9517                                    0        2016.0  \n",
       "\n",
       "[1 rows x 1571 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.columns\n",
    "item_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0e42210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  Username  Mean Score  Completed  avg_Action  avg_Adventure  \\\n",
      "0        1     Xinil        7.37      233.0        7.68           7.90   \n",
      "1       20    vondur        8.06       94.0        8.02           8.24   \n",
      "2       66    Hiromi        7.53      148.0        7.49           7.31   \n",
      "3       82    Achtor        7.17      153.0        7.36           7.71   \n",
      "4      112  luffykun        8.77      125.0        8.60           8.36   \n",
      "\n",
      "   avg_Avant Garde  avg_Award Winning  avg_Boys Love  avg_Comedy  ...  \\\n",
      "0             8.00               8.18           7.06        7.02  ...   \n",
      "1             9.00               8.43           7.06        7.77  ...   \n",
      "2             7.00               7.90           7.06        7.46  ...   \n",
      "3             8.80               8.25           7.06        7.05  ...   \n",
      "4             7.93               9.80           7.06        8.67  ...   \n",
      "\n",
      "   Age_Group__Gen_X  Age_Group__Boomers_Plus  Category_Classic_Era_Fans  \\\n",
      "0                 1                        0                          0   \n",
      "1                 1                        0                          0   \n",
      "2                 0                        0                          0   \n",
      "3                 1                        0                          0   \n",
      "4                 1                        0                          0   \n",
      "\n",
      "   Category_Gen_Alpha_Viewers  Category_Millennial_Favorites  \\\n",
      "0                           0                              0   \n",
      "1                           0                              0   \n",
      "2                           0                              0   \n",
      "3                           0                              0   \n",
      "4                           0                              0   \n",
      "\n",
      "   Category_Retro_Anime_Lovers  Category_Zoomer_Picks  Gender_Female  \\\n",
      "0                            0                      0              0   \n",
      "1                            0                      0              0   \n",
      "2                            0                      0              0   \n",
      "3                            0                      0              0   \n",
      "4                            0                      0              0   \n",
      "\n",
      "   Gender_Male  Gender_Non-Binary  \n",
      "0            1                  0  \n",
      "1            1                  0  \n",
      "2            1                  0  \n",
      "3            1                  0  \n",
      "4            1                  0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None, dtype=int)\n",
    "\n",
    "# Fit and transform the 'Gender' column\n",
    "gender_encoded = encoder.fit_transform(user_data[['Gender']])\n",
    "\n",
    "# Get the column names for the encoded features\n",
    "gender_columns = encoder.get_feature_names_out(['Gender'])\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded, columns=gender_columns)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "user_data = pd.concat([user_data, gender_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'Gender' column if no longer needed\n",
    "user_data.drop(columns=['Gender'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d28877d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R - 17+ (violence & profanity)', 'R - 17+ (violence & profanity)',\n",
       "       'PG-13 - Teens 13 or older', ..., 'PG-13 - Teens 13 or older',\n",
       "       'PG-13 - Teens 13 or older', 'PG-13 - Teens 13 or older'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5d8dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71278, 40)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9dcd0112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Mean Score', 'Completed', 'avg_Action',\n",
       "       'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks', 'Gender_Female', 'Gender_Male',\n",
       "       'Gender_Non-Binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48596c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Genres',\n",
       "       'Synopsis', 'Episodes', 'Aired', 'Premiered',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1571)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2b9f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id                                                                                       0\n",
       "Name                                                                                           0\n",
       "English name                                                                                   0\n",
       "Other name                                                                                     0\n",
       "Score                                                                                       5183\n",
       "                                                                                            ... \n",
       "Studio_trenova                                                                                 0\n",
       "Studio_ufotable                                                                                0\n",
       "Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive       0\n",
       "Studio_ufotable, feel., Studio Flag                                                            0\n",
       "Release_Year                                                                                   0\n",
       "Length: 1571, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "item_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a067f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                             Name             English name  \\\n",
      "0         1                     Cowboy Bebop             Cowboy Bebop   \n",
      "1         5  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie   \n",
      "2         6                           Trigun                   Trigun   \n",
      "3         7               Witch Hunter Robin       Witch Hunter Robin   \n",
      "4         8                   Bouken Ou Beet   Beet the Vandel Buster   \n",
      "\n",
      "                         Other name  Score  \\\n",
      "0                         カウボーイビバップ   8.75   \n",
      "1                    カウボーイビバップ 天国の扉   8.38   \n",
      "2                             トライガン   8.22   \n",
      "3  Witch Hunter ROBIN (ウイッチハンターロビン)   7.25   \n",
      "4                            冒険王ビィト   6.94   \n",
      "\n",
      "                                            Synopsis    Source  \\\n",
      "0  Crime is timeless. By the year 2071, humanity ...  Original   \n",
      "1  Another day, another bounty—such is the life o...  Original   \n",
      "2  Vash the Stampede is the man with a $$60,000,0...     Manga   \n",
      "3  Robin Sena is a powerful craft user drafted in...  Original   \n",
      "4  It is the dark century and the people are suff...     Manga   \n",
      "\n",
      "                           Rating  Rank  Popularity  ...  \\\n",
      "0  R - 17+ (violence & profanity)    41          43  ...   \n",
      "1  R - 17+ (violence & profanity)   189         602  ...   \n",
      "2       PG-13 - Teens 13 or older   328         246  ...   \n",
      "3       PG-13 - Teens 13 or older  2764        1795  ...   \n",
      "4                   PG - Children  4240        5126  ...   \n",
      "\n",
      "   Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
      "0                                 0                       0   \n",
      "1                                 0                       0   \n",
      "2                                 0                       0   \n",
      "3                                 0                       0   \n",
      "4                                 0                       0   \n",
      "\n",
      "   Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
      "0                      0                    0                  0   \n",
      "1                      0                    0                  0   \n",
      "2                      0                    0                  0   \n",
      "3                      0                    0                  0   \n",
      "4                      0                    0                  0   \n",
      "\n",
      "   Studio_trenova  Studio_ufotable  \\\n",
      "0               0                0   \n",
      "1               0                0   \n",
      "2               0                0   \n",
      "3               0                0   \n",
      "4               0                0   \n",
      "\n",
      "   Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
      "0                                                  0                                          \n",
      "1                                                  0                                          \n",
      "2                                                  0                                          \n",
      "3                                                  0                                          \n",
      "4                                                  0                                          \n",
      "\n",
      "   Studio_ufotable, feel., Studio Flag  Release_Year  \n",
      "0                                    0        1998.0  \n",
      "1                                    0        2001.0  \n",
      "2                                    0        1998.0  \n",
      "3                                    0        2002.0  \n",
      "4                                    0        2004.0  \n",
      "\n",
      "[5 rows x 1562 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that drops specified columns from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    columns_to_drop : list of str\n",
    "        List of column names to drop by default.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns_to_drop=None):\n",
    "        self.columns_to_drop = columns_to_drop if columns_to_drop else []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting required for this transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Drops the specified columns from the DataFrame.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            Transformed DataFrame with specified columns dropped\n",
    "        \"\"\"\n",
    "        X_transformed = X.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "        return X_transformed\n",
    "\n",
    "# Define the default columns to drop\n",
    "default_columns_to_drop = [\n",
    "    \"Genres\", \"Episodes\", \"Rating_UNKNOWN\", \"Producers\", \"Aired\",\n",
    "    \"Premiered\", \"Status\", \"Studios\", \"Licensors\", \"Duration\"\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('column_dropper', ColumnDropper(columns_to_drop=default_columns_to_drop))\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the item_data DataFrame\n",
    "filtered_item_data_df = pipeline.fit_transform(item_data)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_item_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e1ea698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Synopsis',\n",
       "       'Source', 'Rating', 'Rank', 'Popularity',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1562)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5df5f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>Studio_pH Studio, D &amp; D Pictures</th>\n",
       "      <th>Studio_pH Studio, Noovo</th>\n",
       "      <th>Studio_production doA</th>\n",
       "      <th>Studio_studio MOTHER</th>\n",
       "      <th>Studio_studio YOG</th>\n",
       "      <th>Studio_trenova</th>\n",
       "      <th>Studio_ufotable</th>\n",
       "      <th>Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive</th>\n",
       "      <th>Studio_ufotable, feel., Studio Flag</th>\n",
       "      <th>Release_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>52</td>\n",
       "      <td>Kidou Tenshi Angelic Layer</td>\n",
       "      <td>Battle Doll Angelic Layer</td>\n",
       "      <td>機動天使エンジェリックレイヤー</td>\n",
       "      <td>7.26</td>\n",
       "      <td>12-year-old Misaki Suzuhara has just gotten in...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>2727</td>\n",
       "      <td>2707</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>17985</td>\n",
       "      <td>Kero Kero Keroppi no Bokutachi no Takaramono</td>\n",
       "      <td>Keroppi in Our Treasure</td>\n",
       "      <td>けろけろけろっぴのぼくたちのたからもの</td>\n",
       "      <td>5.49</td>\n",
       "      <td>Keroppi finds a sparkling stone which ends up ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>G - All Ages</td>\n",
       "      <td>10804</td>\n",
       "      <td>15274</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16786</th>\n",
       "      <td>48452</td>\n",
       "      <td>Powerful Pro Yakyuu: Powerful Koukou-hen</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>パワフルプロ野球 パワフル高校編</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The story will center around a protagonist who...</td>\n",
       "      <td>Game</td>\n",
       "      <td>G - All Ages</td>\n",
       "      <td>18978</td>\n",
       "      <td>16927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1238</td>\n",
       "      <td>One Piece: Mamore! Saigo no Dai Butai</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>ワンピース守れ! 最後の大舞台</td>\n",
       "      <td>7.32</td>\n",
       "      <td>For many years, Ex-Marine Lieutenant Randolph ...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>2434</td>\n",
       "      <td>3797</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>13271</td>\n",
       "      <td>Hunter x Hunter Movie 1: Phantom Rouge</td>\n",
       "      <td>Hunter x Hunter: Phantom Rouge</td>\n",
       "      <td>劇場版 HUNTER×HUNTER 緋色の幻影（ファントム・ルージュ）</td>\n",
       "      <td>7.27</td>\n",
       "      <td>After completing their work at Yorknew City, L...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>2705</td>\n",
       "      <td>1170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anime_id                                          Name  \\\n",
       "33           52                    Kidou Tenshi Angelic Layer   \n",
       "7308      17985  Kero Kero Keroppi no Bokutachi no Takaramono   \n",
       "16786     48452      Powerful Pro Yakyuu: Powerful Koukou-hen   \n",
       "1127       1238         One Piece: Mamore! Saigo no Dai Butai   \n",
       "6548      13271        Hunter x Hunter Movie 1: Phantom Rouge   \n",
       "\n",
       "                         English name                           Other name  \\\n",
       "33          Battle Doll Angelic Layer                      機動天使エンジェリックレイヤー   \n",
       "7308          Keroppi in Our Treasure                  けろけろけろっぴのぼくたちのたからもの   \n",
       "16786                         UNKNOWN                     パワフルプロ野球 パワフル高校編   \n",
       "1127                          UNKNOWN                      ワンピース守れ! 最後の大舞台   \n",
       "6548   Hunter x Hunter: Phantom Rouge  劇場版 HUNTER×HUNTER 緋色の幻影（ファントム・ルージュ）   \n",
       "\n",
       "       Score                                           Synopsis   Source  \\\n",
       "33      7.26  12-year-old Misaki Suzuhara has just gotten in...    Manga   \n",
       "7308    5.49  Keroppi finds a sparkling stone which ends up ...  Unknown   \n",
       "16786    NaN  The story will center around a protagonist who...     Game   \n",
       "1127    7.32  For many years, Ex-Marine Lieutenant Randolph ...    Manga   \n",
       "6548    7.27  After completing their work at Yorknew City, L...    Manga   \n",
       "\n",
       "                          Rating   Rank  Popularity  ...  \\\n",
       "33     PG-13 - Teens 13 or older   2727        2707  ...   \n",
       "7308                G - All Ages  10804       15274  ...   \n",
       "16786               G - All Ages  18978       16927  ...   \n",
       "1127   PG-13 - Teens 13 or older   2434        3797  ...   \n",
       "6548   PG-13 - Teens 13 or older   2705        1170  ...   \n",
       "\n",
       "       Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
       "33                                    0                       0   \n",
       "7308                                  0                       0   \n",
       "16786                                 0                       0   \n",
       "1127                                  0                       0   \n",
       "6548                                  0                       0   \n",
       "\n",
       "       Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
       "33                         0                    0                  0   \n",
       "7308                       0                    0                  0   \n",
       "16786                      0                    0                  0   \n",
       "1127                       0                    0                  0   \n",
       "6548                       0                    0                  0   \n",
       "\n",
       "       Studio_trenova  Studio_ufotable  \\\n",
       "33                  0                0   \n",
       "7308                0                0   \n",
       "16786               0                0   \n",
       "1127                0                0   \n",
       "6548                0                0   \n",
       "\n",
       "       Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
       "33                                                     0                                          \n",
       "7308                                                   0                                          \n",
       "16786                                                  0                                          \n",
       "1127                                                   0                                          \n",
       "6548                                                   0                                          \n",
       "\n",
       "       Studio_ufotable, feel., Studio Flag  Release_Year  \n",
       "33                                       0        2001.0  \n",
       "7308                                     0        1994.0  \n",
       "16786                                    0        2021.0  \n",
       "1127                                     0        2003.0  \n",
       "6548                                     0        2013.0  \n",
       "\n",
       "[5 rows x 1562 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.shape\n",
    "filtered_item_data_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e36921f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5183)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df[\"Score\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "961b92d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(filtered_item_data_df['Score'].dropna(), bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f209fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function for the transformation\n",
    "def impute_score_column(filtered_item_data_df):\n",
    "    \"\"\"\n",
    "    Replaces 'UNKNOWN' with NaN in the 'Score' column and imputes missing values using the mean.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filtered_item_data_df : pandas.DataFrame\n",
    "        The DataFrame containing the 'Score' column to be processed.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The DataFrame with the 'Score' column imputed.\n",
    "    \"\"\"\n",
    "    # Replace 'UNKNOWN' with NaN\n",
    "    filtered_item_data_df['Score'] = filtered_item_data_df['Score'].replace('UNKNOWN', pd.NA)\n",
    "    \n",
    "    # Impute missing values with the mean\n",
    "    filtered_item_data_df['Score'] = filtered_item_data_df['Score'].astype(float).fillna(filtered_item_data_df['Score'].astype(float).mean())\n",
    "    \n",
    "    return filtered_item_data_df\n",
    "\n",
    "# Create the FunctionTransformer\n",
    "impute_score_transformer = FunctionTransformer(impute_score_column)\n",
    "\n",
    "# Apply the transformer\n",
    "filtered_item_data_df = impute_score_transformer.transform(filtered_item_data_df)\n",
    "\n",
    "# Verify that there are no missing values left in 'Score'\n",
    "print(filtered_item_data_df['Score'].isna().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03cacdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                             Name             English name  \\\n",
      "0         1                     Cowboy Bebop             Cowboy Bebop   \n",
      "1         5  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie   \n",
      "2         6                           Trigun                   Trigun   \n",
      "3         7               Witch Hunter Robin       Witch Hunter Robin   \n",
      "4         8                   Bouken Ou Beet   Beet the Vandel Buster   \n",
      "\n",
      "                         Other name  Score  \\\n",
      "0                         カウボーイビバップ   8.75   \n",
      "1                    カウボーイビバップ 天国の扉   8.38   \n",
      "2                             トライガン   8.22   \n",
      "3  Witch Hunter ROBIN (ウイッチハンターロビン)   7.25   \n",
      "4                            冒険王ビィト   6.94   \n",
      "\n",
      "                                            Synopsis    Source  \\\n",
      "0  Crime is timeless. By the year 2071, humanity ...  Original   \n",
      "1  Another day, another bounty—such is the life o...  Original   \n",
      "2  Vash the Stampede is the man with a $$60,000,0...     Manga   \n",
      "3  Robin Sena is a powerful craft user drafted in...  Original   \n",
      "4  It is the dark century and the people are suff...     Manga   \n",
      "\n",
      "                           Rating  Rank  Popularity  ...  \\\n",
      "0  R - 17+ (violence & profanity)    41          43  ...   \n",
      "1  R - 17+ (violence & profanity)   189         602  ...   \n",
      "2       PG-13 - Teens 13 or older   328         246  ...   \n",
      "3       PG-13 - Teens 13 or older  2764        1795  ...   \n",
      "4                   PG - Children  4240        5126  ...   \n",
      "\n",
      "   Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
      "0                                 0                       0   \n",
      "1                                 0                       0   \n",
      "2                                 0                       0   \n",
      "3                                 0                       0   \n",
      "4                                 0                       0   \n",
      "\n",
      "   Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
      "0                      0                    0                  0   \n",
      "1                      0                    0                  0   \n",
      "2                      0                    0                  0   \n",
      "3                      0                    0                  0   \n",
      "4                      0                    0                  0   \n",
      "\n",
      "   Studio_trenova  Studio_ufotable  \\\n",
      "0               0                0   \n",
      "1               0                0   \n",
      "2               0                0   \n",
      "3               0                0   \n",
      "4               0                0   \n",
      "\n",
      "   Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
      "0                                                  0                                          \n",
      "1                                                  0                                          \n",
      "2                                                  0                                          \n",
      "3                                                  0                                          \n",
      "4                                                  0                                          \n",
      "\n",
      "   Studio_ufotable, feel., Studio Flag  Release_Year  \n",
      "0                                    0        1998.0  \n",
      "1                                    0        2001.0  \n",
      "2                                    0        1998.0  \n",
      "3                                    0        2002.0  \n",
      "4                                    0        2004.0  \n",
      "\n",
      "[5 rows x 1562 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "def filter_score_and_release_year(df):\n",
    "    \"\"\"\n",
    "    Filters rows where both 'Score' and 'Release_Year' are not null.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[df[\"Score\"].notna() & df[\"Release_Year\"].notna()]\n",
    "\n",
    "# Create the FunctionTransformer\n",
    "filter_transformer = FunctionTransformer(filter_score_and_release_year)\n",
    "\n",
    "# Apply the transformer to the filtered_item_data_df\n",
    "filtered_item_data_df = filter_transformer.transform(filtered_item_data_df)\n",
    "\n",
    "# Verify the result\n",
    "print(filtered_item_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8ed202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_id                                                                                    0\n",
      "Name                                                                                        0\n",
      "English name                                                                                0\n",
      "Other name                                                                                  0\n",
      "Score                                                                                       0\n",
      "                                                                                           ..\n",
      "Studio_trenova                                                                              0\n",
      "Studio_ufotable                                                                             0\n",
      "Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive    0\n",
      "Studio_ufotable, feel., Studio Flag                                                         0\n",
      "Release_Year                                                                                0\n",
      "Length: 1562, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_item_data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92e25c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19848, 1562)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7775449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Mean Score', 'Completed', 'avg_Action',\n",
       "       'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks', 'Gender_Female', 'Gender_Male',\n",
       "       'Gender_Non-Binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11a73dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Synopsis',\n",
       "       'Source', 'Rating', 'Rank', 'Popularity',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1562)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f5dfc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Username', 'Gender', 'Mean Score', 'Completed', 'Birth_Year',\n",
       "       'user_id', 'anime_id', 'Anime Title', 'rating', 'Genres',\n",
       "       'Genre_Action', 'Genre_Adventure', 'Genre_Avant Garde',\n",
       "       'Genre_Award Winning', 'Genre_Boys Love', 'Genre_Comedy', 'Genre_Drama',\n",
       "       'Genre_Ecchi', 'Genre_Erotica', 'Genre_Fantasy', 'Genre_Girls Love',\n",
       "       'Genre_Gourmet', 'Genre_Hentai', 'Genre_Horror', 'Genre_Mystery',\n",
       "       'Genre_Romance', 'Genre_Sci-Fi', 'Genre_Slice of Life', 'Genre_Sports',\n",
       "       'Genre_Supernatural', 'Genre_Suspense'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2284909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing 'UNKNOWN': ['English name', 'Other name', 'Scored By']\n"
     ]
    }
   ],
   "source": [
    "# Check if any column in filtered_item_data_df contains the value 'UNKNOWN'\n",
    "columns_with_unknown = filtered_item_data_df.columns[filtered_item_data_df.isin(['UNKNOWN']).any()]\n",
    "\n",
    "# Print the columns that contain 'UNKNOWN'\n",
    "print(\"Columns containing 'UNKNOWN':\", list(columns_with_unknown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e65f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances with 'UNKNOWN' values: 15974\n"
     ]
    }
   ],
   "source": [
    "unknown_counts = filtered_item_data_df.isin(['UNKNOWN']).sum().sum()\n",
    "print(f\"Total instances with 'UNKNOWN' values: {unknown_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3886534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_training_data(user_input_df, user_data_df, filtered_item_data_df):\n",
    "    \"\"\"\n",
    "    Prepares training data for a neural network using sparse matrices during processing,\n",
    "    then converts back to dense arrays in the output.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_input_df : DataFrame\n",
    "        Contains user ratings for anime with columns including user_id, anime_id, rating\n",
    "    user_data_df : DataFrame\n",
    "        Contains user demographic data and average genre ratings\n",
    "    filtered_item_data_df : DataFrame\n",
    "        Contains anime metadata including genres, types, and ratings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary containing:\n",
    "        - 'X_U': User features array (dense)\n",
    "        - 'X_A': Anime features array (dense)\n",
    "        - 'Y': Rating values array\n",
    "        - 'X_U_columns': List of column names for user features\n",
    "        - 'X_A_columns': List of column names for anime features\n",
    "        - 'Y_column': Name of the rating column\n",
    "        - 'X_U_indices': List of indices for user features\n",
    "        - 'X_A_indices': List of indices for anime features\n",
    "        - 'Y_index': Index of the rating column\n",
    "        - 'merged_df': The merged and cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Step 1: Merge dataframes with suffixes to handle column conflicts\n",
    "    merged_df = user_input_df.merge(user_data_df, on='user_id', suffixes=('', '_user'))\n",
    "    merged_df = merged_df.merge(filtered_item_data_df, on='anime_id', suffixes=('', '_anime'))\n",
    "    \n",
    "    # Step 2: Identify columns to drop (non-numerical or identifiers)\n",
    "    columns_to_drop = ['Username', 'user_id', 'anime_id', 'Anime Title', \n",
    "                     'Name', 'English name', 'Other name', 'Synopsis', \n",
    "                     'Source', \"Scored by\", 'Image URL']\n",
    "    \n",
    "    # Only drop columns that actually exist in the merged dataframe\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in merged_df.columns]\n",
    "    \n",
    "    # Drop identified columns\n",
    "    cleaned_df = merged_df.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Step 3: Define columns for each component\n",
    "    X_U_columns = [\n",
    "        'Mean Score', 'Completed',\n",
    "        'avg_Action', 'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
    "        'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
    "        'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
    "        'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
    "        'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
    "        'Gender_Female', 'Gender_Male', 'Gender_Non-Binary','Age',\n",
    "        'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
    "        'Category_Millennial_Favorites', \n",
    "        'Category_Retro_Anime_Lovers', \n",
    "        'Category_Zoomer_Picks'\n",
    "    ]\n",
    "    \n",
    "    excluded_columns = ['anime_id', 'Name', 'English name', 'Other name',\n",
    "                      'Score', \"Synopsis\", \"Source\", \"Rank\",\"Rating\"]\n",
    "    \n",
    "    X_A_columns = [col for col in filtered_item_data_df.columns \n",
    "                  if col not in excluded_columns and col in cleaned_df.columns]\n",
    "    X_U_columns = [col for col in X_U_columns if col in cleaned_df.columns]\n",
    "    \n",
    "    Y_column = \"rating\"\n",
    "    if Y_column not in cleaned_df.columns:\n",
    "        raise ValueError(f\"Rating column '{Y_column}' not found in merged dataframe\")\n",
    "    \n",
    "    # Step 4: Get indices for features\n",
    "    X_U_indices = [cleaned_df.columns.get_loc(col) for col in X_U_columns]\n",
    "    X_A_indices = [cleaned_df.columns.get_loc(col) for col in X_A_columns]\n",
    "    Y_index = cleaned_df.columns.get_loc(Y_column)\n",
    "    \n",
    "    # Step 5: Process with sparse matrices\n",
    "    # Convert relevant portions to sparse format\n",
    "    X_U_sparse = csr_matrix(cleaned_df.iloc[:, X_U_indices].values)\n",
    "    X_A_sparse = csr_matrix(cleaned_df.iloc[:, X_A_indices].values)\n",
    "    \n",
    "    # Perform sparse operations if needed (e.g., scaling)\n",
    "    # ... (your sparse-compatible preprocessing here) ...\n",
    "    \n",
    "    # Convert back to dense for output (if your model requires dense inputs)\n",
    "    X_U = X_U_sparse.toarray()\n",
    "    X_A = X_A_sparse.toarray()\n",
    "    Y = cleaned_df.iloc[:, Y_index].values\n",
    "    \n",
    "    return {\n",
    "        \"X_U\": X_U,\n",
    "        \"X_A\": X_A,\n",
    "        \"Y\": Y,\n",
    "        \"X_U_columns\": X_U_columns,\n",
    "        \"X_A_columns\": X_A_columns,\n",
    "        \"Y_column\": Y_column,\n",
    "        \"X_U_indices\": X_U_indices,\n",
    "        \"X_A_indices\": X_A_indices,\n",
    "        \"Y_index\": Y_index,\n",
    "        \"merged_df\": cleaned_df,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "486c4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "# Select a smaller dataframe with 200000 samples from user_input\n",
    "user_input_sample = user_input.sample(n=200000, random_state=42)\n",
    "\n",
    "# Ensure all columns in user_input_sample, user_data, and filtered_item_data_df are numeric\n",
    "user_input_sample = user_input_sample.select_dtypes(include=[np.number])\n",
    "user_data = user_data.select_dtypes(include=[np.number])\n",
    "filtered_item_data_df = filtered_item_data_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Prepare the training data using the sampled dataframe\n",
    "result = prepare_training_data(user_input_sample, user_data, filtered_item_data_df)\n",
    "\n",
    "# Access the prepared data\n",
    "X_U = result['X_U']  # User features\n",
    "X_A = result['X_A']  # Anime features\n",
    "Y = result['Y']      # Ratings\n",
    "\n",
    "# You can also access indices if needed\n",
    "X_U_indices = result['X_U_indices']\n",
    "X_A_indices = result['X_A_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fbf410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['X_U_columns']) # Number of user feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed29ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ead081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1551)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dad9a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8bb3363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9, 10,  9, 10,  7,  9,  2,  8,  8])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d561d94",
   "metadata": {},
   "source": [
    "# Neural Network for implementing Content Based Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30fd1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23c72040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 120000 samples\n",
      "Validation set: 40000 samples\n",
      "Test set: 40000 samples\n",
      "(120000, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# --- Scaling the data ---\n",
    "# Create scalers\n",
    "user_scaler = StandardScaler()\n",
    "anime_scaler = StandardScaler()\n",
    "\n",
    "# Ensure all columns in X_A are numeric\n",
    "# Convert categorical columns (e.g., 'Rating') to numeric using one-hot encoding\n",
    "#X_A_df = pd.DataFrame(X_A, columns=result['X_A_columns'])  # Convert X_A to DataFrame for easier processing\n",
    "\n",
    "# print(X_A_df.columns)  # Check the columns after encoding\n",
    "# Scale the features\n",
    "X_U_scaled = user_scaler.fit_transform(X_U)\n",
    "X_A_scaled = anime_scaler.fit_transform(X_A)\n",
    "\n",
    "# --- Splitting the scaled data ---\n",
    "# First split: 80% train+val, 20% test\n",
    "X_U_temp, X_U_test, X_A_temp, X_A_test, Y_temp, Y_test = train_test_split(\n",
    "    X_U_scaled, X_A_scaled, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 75% train, 25% validation (results in 60% train, 20% val, 20% test overall)\n",
    "X_U_train, X_U_val, X_A_train, X_A_val, Y_train, Y_val = train_test_split(\n",
    "    X_U_temp, X_A_temp, Y_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_U_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_U_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_U_test.shape[0]} samples\")\n",
    "\n",
    "print(X_U_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "507e6f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1551</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_nn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,472</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_nn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">442,336</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_nn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ item_nn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1551\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_nn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m53,472\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_nn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m442,336\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_nn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ item_nn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,808</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m495,808\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">494,016</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m494,016\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - loss: 26.7930 - mean_absolute_error: 3.3946 - val_loss: 2.2129 - val_mean_absolute_error: 1.1155 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - loss: 2.1736 - mean_absolute_error: 1.1326 - val_loss: 1.9506 - val_mean_absolute_error: 1.0526 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 2.0133 - mean_absolute_error: 1.0884 - val_loss: 1.9202 - val_mean_absolute_error: 1.0455 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 1.9366 - mean_absolute_error: 1.0653 - val_loss: 1.8991 - val_mean_absolute_error: 1.0310 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 1.8553 - mean_absolute_error: 1.0422 - val_loss: 1.8689 - val_mean_absolute_error: 1.0265 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 1.7961 - mean_absolute_error: 1.0254 - val_loss: 1.8699 - val_mean_absolute_error: 1.0268 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2381/3750\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.7454 - mean_absolute_error: 1.0108"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     67\u001b[39m model.summary()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_U_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_A_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_U_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_A_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     78\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Anshuman Raj\\OneDrive\\Desktop\\ML grp project\\ml_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- TensorFlow model ---\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define inputs for user and item features\n",
    "user_input = tf.keras.Input(shape=(X_U_train.shape[1],), name=\"user_input\")\n",
    "item_input = tf.keras.Input(shape=(X_A_train.shape[1],), name=\"item_input\")\n",
    "\n",
    "# Define user network with dropout for regularization\n",
    "user_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='linear')\n",
    "], name=\"user_nn\")\n",
    "\n",
    "# Define item network with dropout for regularization\n",
    "item_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='linear')\n",
    "], name=\"item_nn\")\n",
    "\n",
    "# Pass inputs through respective networks\n",
    "vu = user_nn(user_input)\n",
    "va = item_nn(item_input)\n",
    "\n",
    "# Compute dot product\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, va])\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model([user_input, item_input], output)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_U_train, X_A_train],\n",
    "    Y_train,\n",
    "    validation_data=([X_U_val, X_A_val], Y_val),\n",
    "    epochs=60,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7916 - mean_absolute_error: 1.0078\n",
      "Test loss (MSE): 1.7994484901428223\n",
      "Test MAE: 1.0119624137878418\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = model.evaluate([X_U_test, X_A_test], Y_test, verbose=1)\n",
    "print(f\"Test loss (MSE): {test_results[0]}\")\n",
    "print(f\"Test MAE: {test_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ad13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/recommender_model_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/recommender_model_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_model/recommender_model_6'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 32), dtype=tf.float32, name='user_input'), TensorSpec(shape=(None, 1551), dtype=tf.float32, name='item_input')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2637972993424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972991888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972990544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972992656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972989968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972991696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972989584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972988816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972994192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972988624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972989008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972990160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972986128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972985744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972987472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972985552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972988240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972983056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972984016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972982480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972982288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972991120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972984400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972982864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972979984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972981136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972981328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972980560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972983440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2637972981904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254331344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254331536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254331920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254333264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254332496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254332112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254330768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635254330384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save in TensorFlow SavedModel format\n",
    "model.export('../saved_model/recommender_model_6')\n",
    "\n",
    "# Save in HDF5 format\n",
    "model.save('../saved_model/recommender_model_6.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9301f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save in TensorFlow SavedModel format\n",
    "# model.export('../saved_model/recommender_model_2')\n",
    "\n",
    "# # Save in HDF5 format\n",
    "# model.save('../recommender_model_2.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b724a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('../saved_model/recommender_model_6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0ca098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25989455,  0.32317614,  0.24692126,  0.51687892, -0.1317057 ,\n",
       "        -0.28708446,  1.57206042, -0.27704778,  0.16021278,  0.157398  ,\n",
       "         0.07581517,  0.29228819,  0.25436898,  0.71397845,  0.11641071,\n",
       "         0.16433943,  0.25063178, -0.08446916,  0.29093007,  0.14058532,\n",
       "         0.09544477,  0.11204122,  0.44291244, -0.6441875 ,  0.65238654,\n",
       "        -0.07278681, -0.27320431,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.11070908, -0.39802264, -0.82766483, -1.06390135,  1.00888589,\n",
       "        -0.63833223, -1.10495582, -0.98105748, -1.56264593, -0.81415629,\n",
       "        -3.2394846 , -1.25647216, -3.49930131,  0.5472529 ,  0.08170883,\n",
       "         0.0280102 , -1.25054341, -1.64605076, -0.42125418, -0.54687925,\n",
       "        -0.60209419, -0.98151224, -1.66798113,  1.55234306, -1.53283358,\n",
       "        -0.07278681, -0.00468354,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.60325062, -0.81813842,  0.22304156,  1.12842165,  0.84594423,\n",
       "         0.71648059,  0.16356495,  0.88860762,  0.42821302, -3.49460518,\n",
       "         0.07581517,  0.93473693,  0.11566523,  0.08630578,  0.08170883,\n",
       "        -1.00419677,  0.59341981,  1.04078816,  0.93306341,  1.33082249,\n",
       "         0.79298373, -0.05619777,  0.22187647, -0.6441875 ,  0.65238654,\n",
       "        -0.07278681, -0.32690847,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.32154778, -0.75745503, -1.35301802, -0.51005133, -0.62053067,\n",
       "        -0.42507465,  0.16356495, -0.41554149, -0.59274029, -0.51054558,\n",
       "         0.07581517, -0.41899434, -0.46515673,  0.5472529 ,  0.08170883,\n",
       "         0.56358929,  0.28609261, -0.36004239,  0.38433128,  0.17136732,\n",
       "         0.12334633, -0.52486354,  0.35449805, -0.6441875 ,  0.65238654,\n",
       "        -0.07278681, -0.11209185,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.14891875, -0.45870603, -0.09933426, -0.44082008,  0.60153175,\n",
       "         0.2021535 ,  0.16356495, -0.2539655 , -0.09502555, -0.24163323,\n",
       "        -2.59935467, -0.25838216, -1.76550441, -0.43348566,  0.08170883,\n",
       "         0.29093085, -0.05669543, -0.45190013, -0.11770024, -1.23434382,\n",
       "        -0.60209419, -0.14031727,  0.06715128, -0.6441875 ,  0.65238654,\n",
       "        -0.07278681, -0.27320431,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_U_test[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b345239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.69920481, -0.38654972, -0.72123611, ..., -0.00223607,\n",
       "        -0.01245086,  0.75442207],\n",
       "       [ 1.5770615 , -0.38654972, -0.71797694, ..., -0.00223607,\n",
       "        -0.01245086, -0.7860036 ],\n",
       "       [-0.47928185, -0.04080992, -0.29046938, ..., -0.00223607,\n",
       "        -0.01245086,  1.87473164],\n",
       "       [-0.72674102, -0.25985486,  0.2798146 , ..., -0.00223607,\n",
       "        -0.01245086,  0.05422858],\n",
       "       [-0.7373162 , -0.24332945,  0.3301047 , ..., -0.00223607,\n",
       "        -0.01245086,  0.61438337]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_A_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a41b7802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.839889 ],\n",
       "       [6.181007 ],\n",
       "       [9.0439825],\n",
       "       [7.051241 ],\n",
       "       [7.636688 ],\n",
       "       [7.551433 ],\n",
       "       [7.0224805],\n",
       "       [8.757653 ],\n",
       "       [8.747307 ],\n",
       "       [8.574726 ],\n",
       "       [9.286611 ],\n",
       "       [8.170483 ],\n",
       "       [7.292415 ],\n",
       "       [7.6250687],\n",
       "       [8.081337 ],\n",
       "       [8.288361 ],\n",
       "       [6.3352094],\n",
       "       [7.862419 ],\n",
       "       [7.686511 ],\n",
       "       [8.304533 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions on X-U_test and X-A_test\n",
    "predictions = model.predict([X_U_test[:20], X_A_test[:20]])\n",
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "128f511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  9,  4,  7,  8,  8,  9,  9, 10,  9,  7,  8,  8,  7,  9,  6,\n",
       "        7,  7,  7])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b28c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(12, 4))\\nplt.subplot(1, 2, 1)\\nplt.plot(history.history['loss'], label='Training Loss')\\nplt.plot(history.history['val_loss'], label='Validation Loss')\\nplt.title('Loss Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('Loss (MSE)')\\nplt.legend()\\n\\nplt.subplot(1, 2, 2)\\nplt.plot(history.history['mean_absolute_error'], label='Training MAE')\\nplt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\\nplt.title('Mean Absolute Error Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('MAE')\\nplt.legend()\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Plot training history\n",
    "# Uncomment if you're running in an environment that supports plotting\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "plt.title('Mean Absolute Error Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
