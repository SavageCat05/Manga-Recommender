{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db3612a",
   "metadata": {},
   "source": [
    "# Obtained_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce088793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad86276c",
   "metadata": {},

   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_38568\\192256860.py:3: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  item_data=pd.read_csv(\"Final_Anime_Dataset.csv\")\n"
     ]
    }
   ],

   "source": [
    "import pandas as pd\n",
    "user_data=pd.read_csv(\"Final_User_Dataset.csv\")\n",
    "item_data=pd.read_csv(\"Final_Anime_Dataset.csv\")\n",
    "user_input=pd.read_csv(\"User_input.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25c55f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[user_data.columns[21]].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20eed514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "array([347, 'troublesome4u', 'Male', 8.64, 167.0, 8.84, 8.83, 7.93, 9.56,\n",
       "       7.06, 8.1, 8.67, 8.0, 6.8, 8.47, 7.17, 7.53, 6.47, 8.54, 6.83,\n",
       "       8.57, 8.32, 7.87, 9.0, 8.69, 10.0, 47, 'Gen_X', 0, 1], dtype=object)"

      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.iloc[21, :].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4627a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_data[\"avg_Romance\"] = pd.to_numeric(user_data[\"avg_Romance\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066899aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class GenreRatingTypeConverter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that converts all columns with a specific prefix to numeric data types,\n",
    "    handling non-numeric values by converting them to NaN.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    column_prefix : str, default='avg_'\n",
    "        Prefix used to identify columns for conversion\n",
    "    errors : str, default='coerce'\n",
    "        How to handle errors in conversion:\n",
    "        - 'ignore': leave invalid values as is\n",
    "        - 'raise': raise an exception\n",
    "        - 'coerce': convert invalid values to NaN\n",
    "    downcast : str or None, default=None\n",
    "        Type to downcast to if possible ('integer', 'signed', 'unsigned', 'float')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, column_prefix='avg_', errors='coerce', downcast=None):\n",
    "        self.column_prefix = column_prefix\n",
    "        self.errors = errors\n",
    "        self.downcast = downcast\n",
    "        self.columns_converted_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Identify columns to convert based on prefix.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame\n",
    "        y : array-like, default=None\n",
    "            Not used, present for API consistency\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        # Identify columns starting with the specified prefix\n",
    "        self.columns_converted_ = [col for col in X.columns if col.startswith(self.column_prefix)]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Convert identified columns to numeric types.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame to transform\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            Transformed DataFrame with numeric columns\n",
    "        \"\"\"\n",
    "        X_result = X.copy()\n",
    "        \n",
    "        for column in self.columns_converted_:\n",
    "            X_result[column] = pd.to_numeric(X_result[column], \n",
    "                                             errors=self.errors, \n",
    "                                             downcast=self.downcast)\n",
    "        \n",
    "        return X_result\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"\n",
    "        Get output feature names.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_features : array-like of str or None, default=None\n",
    "            Input features\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list\n",
    "            List of converted column names\n",
    "        \"\"\"\n",
    "        return self.columns_converted_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90724c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_Action: float64\n",
      "avg_Adventure: float64\n",
      "avg_Avant Garde: float64\n",
      "avg_Award Winning: float64\n",
      "avg_Boys Love: float64\n",
      "avg_Comedy: float64\n",
      "avg_Drama: float64\n",
      "avg_Ecchi: float64\n",
      "avg_Erotica: float64\n",
      "avg_Fantasy: float64\n",
      "avg_Girls Love: float64\n",
      "avg_Gourmet: float64\n",
      "avg_Hentai: float64\n",
      "avg_Horror: float64\n",
      "avg_Mystery: float64\n",
      "avg_Romance: float64\n",
      "avg_Sci-Fi: float64\n",
      "avg_Slice of Life: float64\n",
      "avg_Sports: float64\n",
      "avg_Supernatural: float64\n",
      "avg_Suspense: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize the transformer\n",
    "genre_converter = GenreRatingTypeConverter(column_prefix='avg_', errors='coerce')\n",
    "\n",
    "# Apply the transformation\n",
    "user_data = genre_converter.fit_transform(user_data)\n",
    "\n",
    "# Check the data types of converted columns\n",
    "for col in genre_converter.columns_converted_:\n",
    "    print(f\"{col}: {user_data[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278053da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"avg_Romance\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e309d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of avg_Mystery: 1.0 to 10.0\n"
     ]
    }
   ],
   "source": [
    "min_value = user_data['avg_Mystery'].min()\n",
    "max_value = user_data['avg_Mystery'].max()\n",
    "print(f\"Range of avg_Mystery: {min_value} to {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ed4ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[\"avg_Mystery\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a528533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(19848, 1571)"

      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bbd5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Gender', 'Mean Score', 'Completed',\n",
       "       'avg_Action', 'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede8c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>Premiered</th>\n",
       "      <th>...</th>\n",
       "      <th>Type_TV</th>\n",
       "      <th>Type_UNKNOWN</th>\n",
       "      <th>Rating_G - All Ages</th>\n",
       "      <th>Rating_PG - Children</th>\n",
       "      <th>Rating_PG-13 - Teens 13 or older</th>\n",
       "      <th>Rating_R - 17+ (violence &amp; profanity)</th>\n",
       "      <th>Rating_R+ - Mild Nudity</th>\n",
       "      <th>Rating_Rx - Hentai</th>\n",
       "      <th>Rating_UNKNOWN</th>\n",
       "      <th>Release_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>11668</th>\n",
       "      <td>35708</td>\n",
       "      <td>Afureko! AR</td>\n",
=======

       "      <th>17030</th>\n",
       "      <td>49104</td>\n",
       "      <td>Haruka</td>\n",
>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
       "      <td>UNKNOWN</td>\n",
       "      <td>あふれこ! AR</td>\n",
       "      <td>5.13</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Saori was thrown into a voice actor vocational...</td>\n",
       "      <td>3</td>\n",
       "      <td>Oct 18, 2011</td>\n",
       "      <td>UNKNOWN</td>\n",


       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anime_id         Name English name Other name  Score   Genres  \\\n",
       "11668     35708  Afureko! AR      UNKNOWN   あふれこ! AR   5.13  UNKNOWN   \n",
       "\n",
       "                                                Synopsis  Episodes  \\\n",
       "11668  Saori was thrown into a voice actor vocational...         3   \n",
       "\n",
       "              Aired Premiered  ... Studio_pH Studio, D & D Pictures  \\\n",
       "11668  Oct 18, 2011   UNKNOWN  ...                                0   \n",
       "\n",
       "      Studio_pH Studio, Noovo Studio_production doA Studio_studio MOTHER  \\\n",
       "11668                       0                     0                    0   \n",
       "\n",
       "      Studio_studio YOG Studio_trenova Studio_ufotable  \\\n",
       "11668                 0              0               0   \n",
       "\n",
       "       Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
       "11668                                                  0                                          \n",
       "\n",
       "       Studio_ufotable, feel., Studio Flag  Release_Year  \n",
       "11668                                    0        2011.0  \n",
       "\n",
       "[1 rows x 1571 columns]"

      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.columns\n",
    "item_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e42210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  Username  Mean Score  Completed  avg_Action  avg_Adventure  \\\n",
      "0        1     Xinil        7.37      233.0        7.68           7.90   \n",
      "1       20    vondur        8.06       94.0        8.02           8.24   \n",
      "2       66    Hiromi        7.53      148.0        7.49           7.31   \n",
      "3       82    Achtor        7.17      153.0        7.36           7.71   \n",
      "4      112  luffykun        8.77      125.0        8.60           8.36   \n",
      "\n",

      "   avg_Avant Garde  avg_Award Winning  avg_Boys Love  avg_Comedy  ...  \\\n",
      "0             8.00               8.18           7.06        7.02  ...   \n",
      "1             9.00               8.43           7.06        7.77  ...   \n",
      "2             7.00               7.90           7.06        7.46  ...   \n",
      "3             8.80               8.25           7.06        7.05  ...   \n",
      "4             7.93               9.80           7.06        8.67  ...   \n",
      "\n",
      "   Age_Group__Gen_X  Age_Group__Boomers_Plus  Category_Classic_Era_Fans  \\\n",
      "0                 1                        0                          0   \n",
      "1                 1                        0                          0   \n",
      "2                 0                        0                          0   \n",
      "3                 1                        0                          0   \n",
      "4                 1                        0                          0   \n",

      "\n",
      "   Category_Gen_Alpha_Viewers  Category_Millennial_Favorites  \\\n",
      "0                       False                          False   \n",
      "1                       False                          False   \n",
      "2                       False                          False   \n",
      "3                       False                          False   \n",
      "4                       False                          False   \n",
      "\n",
      "   Category_Retro_Anime_Lovers  Category_Zoomer_Picks  Gender_Female  \\\n",

      "0                            0                      0              0   \n",
      "1                            0                      0              0   \n",
      "2                            0                      0              0   \n",
      "3                            0                      0              0   \n",
      "4                            0                      0              0   \n",

      "\n",
      "   Gender_Male  Gender_Non-Binary  \n",
      "0            1                  0  \n",
      "1            1                  0  \n",
      "2            1                  0  \n",
      "3            1                  0  \n",
      "4            1                  0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None, dtype=int)\n",
    "\n",
    "# Fit and transform the 'Gender' column\n",
    "gender_encoded = encoder.fit_transform(user_data[['Gender']])\n",
    "\n",
    "# Get the column names for the encoded features\n",
    "gender_columns = encoder.get_feature_names_out(['Gender'])\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded, columns=gender_columns)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "user_data = pd.concat([user_data, gender_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'Gender' column if no longer needed\n",
    "user_data.drop(columns=['Gender'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28877d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R - 17+ (violence & profanity)', 'R - 17+ (violence & profanity)',\n",
       "       'PG-13 - Teens 13 or older', ..., 'PG-13 - Teens 13 or older',\n",
       "       'PG-13 - Teens 13 or older', 'PG-13 - Teens 13 or older'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d8dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(71278, 40)"

      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dcd0112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Mean Score', 'Completed', 'avg_Action',\n",
       "       'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks', 'Gender_Female', 'Gender_Male',\n",
       "       'Gender_Non-Binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48596c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Genres',\n",

       "       'Synopsis', 'Episodes', 'Aired', 'Premiered',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1571)"

      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2b9f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "anime_id                                                                                       0\n",
       "Name                                                                                           0\n",
       "English name                                                                                   0\n",
       "Other name                                                                                     0\n",
       "Score                                                                                       5183\n",
       "                                                                                            ... \n",
       "Studio_trenova                                                                                 0\n",
       "Studio_ufotable                                                                                0\n",
       "Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive       0\n",
       "Studio_ufotable, feel., Studio Flag                                                            0\n",
       "Release_Year                                                                                   0\n",
       "Length: 1571, dtype: int64"

      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "item_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a067f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                             Name             English name  \\\n",
      "0         1                     Cowboy Bebop             Cowboy Bebop   \n",
      "1         5  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie   \n",
      "2         6                           Trigun                   Trigun   \n",
      "3         7               Witch Hunter Robin       Witch Hunter Robin   \n",
      "4         8                   Bouken Ou Beet   Beet the Vandel Buster   \n",
      "\n",
      "                         Other name  Score  \\\n",
      "0                         カウボーイビバップ   8.75   \n",
      "1                    カウボーイビバップ 天国の扉   8.38   \n",
      "2                             トライガン   8.22   \n",
      "3  Witch Hunter ROBIN (ウイッチハンターロビン)   7.25   \n",
      "4                            冒険王ビィト   6.94   \n",
      "\n",
      "                                            Synopsis    Source  \\\n",
      "0  Crime is timeless. By the year 2071, humanity ...  Original   \n",
      "1  Another day, another bounty—such is the life o...  Original   \n",
      "2  Vash the Stampede is the man with a $$60,000,0...     Manga   \n",
      "3  Robin Sena is a powerful craft user drafted in...  Original   \n",
      "4  It is the dark century and the people are suff...     Manga   \n",
      "\n",
      "                           Rating  Rank  Popularity  ...  \\\n",
      "0  R - 17+ (violence & profanity)    41          43  ...   \n",
      "1  R - 17+ (violence & profanity)   189         602  ...   \n",
      "2       PG-13 - Teens 13 or older   328         246  ...   \n",
      "3       PG-13 - Teens 13 or older  2764        1795  ...   \n",
      "4                   PG - Children  4240        5126  ...   \n",
      "\n",
      "   Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
      "0                                 0                       0   \n",
      "1                                 0                       0   \n",
      "2                                 0                       0   \n",
      "3                                 0                       0   \n",
      "4                                 0                       0   \n",
      "\n",
      "   Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
      "0                      0                    0                  0   \n",
      "1                      0                    0                  0   \n",
      "2                      0                    0                  0   \n",
      "3                      0                    0                  0   \n",
      "4                      0                    0                  0   \n",
      "\n",
      "   Studio_trenova  Studio_ufotable  \\\n",
      "0               0                0   \n",
      "1               0                0   \n",
      "2               0                0   \n",
      "3               0                0   \n",
      "4               0                0   \n",
      "\n",
      "   Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
      "0                                                  0                                          \n",
      "1                                                  0                                          \n",
      "2                                                  0                                          \n",
      "3                                                  0                                          \n",
      "4                                                  0                                          \n",
      "\n",
      "   Studio_ufotable, feel., Studio Flag  Release_Year  \n",
      "0                                    0        1998.0  \n",
      "1                                    0        2001.0  \n",
      "2                                    0        1998.0  \n",
      "3                                    0        2002.0  \n",
      "4                                    0        2004.0  \n",
      "\n",
      "[5 rows x 1562 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that drops specified columns from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    columns_to_drop : list of str\n",
    "        List of column names to drop by default.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns_to_drop=None):\n",
    "        self.columns_to_drop = columns_to_drop if columns_to_drop else []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting required for this transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Drops the specified columns from the DataFrame.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Input DataFrame\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            Transformed DataFrame with specified columns dropped\n",
    "        \"\"\"\n",
    "        X_transformed = X.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "        return X_transformed\n",
    "\n",
    "# Define the default columns to drop\n",
    "default_columns_to_drop = [\n",
    "    \"Genres\", \"Episodes\", \"Rating_UNKNOWN\", \"Producers\", \"Aired\",\n",
    "    \"Premiered\", \"Status\", \"Studios\", \"Licensors\", \"Duration\"\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('column_dropper', ColumnDropper(columns_to_drop=default_columns_to_drop))\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the item_data DataFrame\n",
    "filtered_item_data_df = pipeline.fit_transform(item_data)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_item_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e1ea698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Synopsis',\n",

       "       'Source', 'Rating', 'Rank', 'Popularity',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1562)"


      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5df5f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Source</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>Type_Special</th>\n",
       "      <th>Type_TV</th>\n",
       "      <th>Type_UNKNOWN</th>\n",
       "      <th>Rating_G - All Ages</th>\n",
       "      <th>Rating_PG - Children</th>\n",
       "      <th>Rating_PG-13 - Teens 13 or older</th>\n",
       "      <th>Rating_R - 17+ (violence &amp; profanity)</th>\n",
       "      <th>Rating_R+ - Mild Nudity</th>\n",
       "      <th>Rating_Rx - Hentai</th>\n",
       "      <th>Release_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>4357</th>\n",
       "      <td>6117</td>\n",
       "      <td>Gokujou!! Mecha Mote Iinchou</td>\n",
       "      <td>The Best!! Extremely Cool Student Council Pres...</td>\n",
       "      <td>極上!!めちゃモテ委員長</td>\n",
       "      <td>6.33</td>\n",
       "      <td>Mimi Kitagami is a kind, level-headed girl who...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG - Children</td>\n",
       "      <td>7207</td>\n",
       "      <td>6601</td>\n",
=======

       "      <th>18349</th>\n",
       "      <td>52346</td>\n",
       "      <td>Sayonara Hero</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>さよならヒーロー</td>\n",
       "      <td>6.11</td>\n",
       "      <td>This song follows in the same theme of \"shit d...</td>\n",
       "      <td>Mixed media</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>0</td>\n",
       "      <td>15358</td>\n",

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17269</th>\n",
       "      <td>49825</td>\n",
       "      <td>Levitating</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Levitating</td>\n",
       "      <td>6.49</td>\n",
       "      <td>Japanese animated music video featuring the so...</td>\n",
       "      <td>Original</td>\n",
       "      <td>G - All Ages</td>\n",
       "      <td>0</td>\n",
       "      <td>14557</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>23427</td>\n",
       "      <td>Oneechan ga Kita: Hajimete no… Kitaa!</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>お姉ちゃんが来た 初めての... キター!</td>\n",
       "      <td>6.44</td>\n",
       "      <td>This episode shows Ichika's and Tomoya's first...</td>\n",
       "      <td>4-koma manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>6686</td>\n",
       "      <td>4078</td>\n",
       "      <td>...</td>\n",

       "      <td>0</td>\n",
       "      <td>14854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9516</th>\n",
       "      <td>30709</td>\n",
       "      <td>Kamisama Hajimemashita: Kako-hen</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>神様はじめました～過去編～</td>\n",
       "      <td>8.39</td>\n",
       "      <td>While playing in the snow one day at her shrin...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
<<<<<<< HEAD
       "      <td>181</td>\n",
       "      <td>1365</td>\n",
=======
       "      <td>9601</td>\n",
       "      <td>11559</td>\n",

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>1732</th>\n",
       "      <td>1906</td>\n",
       "      <td>Harukanaru Toki no Naka de: Maihitoyo</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>劇場版 遙かなる時空（とき）の中で 舞一夜（まいひとよ）</td>\n",
       "      <td>7.13</td>\n",
       "      <td>One rainy day, Akane crosses path with a kind ...</td>\n",
       "      <td>Visual novel</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>3396</td>\n",
       "      <td>7492</td>\n",
=======
       "      <th>11111</th>\n",
       "      <td>34566</td>\n",
       "      <td>Boruto: Naruto Next Generations</td>\n",
       "      <td>Boruto: Naruto Next Generations</td>\n",
       "      <td>BORUTO -NARUTO NEXT GENERATIONS-</td>\n",
       "      <td>6.06</td>\n",
       "      <td>Following the successful end of the Fourth Shi...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>8551</td>\n",
       "      <td>193</td>\n",

       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>20001</td>\n",
       "      <td>Mouretsu Atarou</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>もーれつア太郎</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Based on a manga of Akatsuka Fujio.\\n\\nBatsugo...</td>\n",
       "      <td>Manga</td>\n",
       "      <td>G - All Ages</td>\n",
       "      <td>18289</td>\n",
       "      <td>15236</td>\n",

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",

       "      <td>0</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       anime_id                                   Name  \\\n",
       "4357       6117           Gokujou!! Mecha Mote Iinchou   \n",
       "17269     49825                             Levitating   \n",
       "8313      23427  Oneechan ga Kita: Hajimete no… Kitaa!   \n",
       "9516      30709       Kamisama Hajimemashita: Kako-hen   \n",
       "1732       1906  Harukanaru Toki no Naka de: Maihitoyo   \n",
       "\n",
       "                                            English name  \\\n",
       "4357   The Best!! Extremely Cool Student Council Pres...   \n",
       "17269                                            UNKNOWN   \n",
       "8313                                             UNKNOWN   \n",
       "9516                                             UNKNOWN   \n",
       "1732                                             UNKNOWN   \n",
       "\n",
       "                         Other name  Score  \\\n",
       "4357                   極上!!めちゃモテ委員長   6.33   \n",
       "17269                    Levitating   6.49   \n",
       "8313          お姉ちゃんが来た 初めての... キター!   6.44   \n",
       "9516                  神様はじめました～過去編～   8.39   \n",
       "1732   劇場版 遙かなる時空（とき）の中で 舞一夜（まいひとよ）   7.13   \n",
       "\n",
       "                                                Synopsis        Source  \\\n",
       "4357   Mimi Kitagami is a kind, level-headed girl who...         Manga   \n",
       "17269  Japanese animated music video featuring the so...      Original   \n",
       "8313   This episode shows Ichika's and Tomoya's first...  4-koma manga   \n",
       "9516   While playing in the snow one day at her shrin...         Manga   \n",
       "1732   One rainy day, Akane crosses path with a kind ...  Visual novel   \n",
       "\n",
       "                          Rating  Rank  Popularity  ...  \\\n",
       "4357               PG - Children  7207        6601  ...   \n",
       "17269               G - All Ages     0       14557  ...   \n",
       "8313   PG-13 - Teens 13 or older  6686        4078  ...   \n",
       "9516   PG-13 - Teens 13 or older   181        1365  ...   \n",
       "1732   PG-13 - Teens 13 or older  3396        7492  ...   \n",
       "\n",
       "       Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
       "4357                                  0                       0   \n",
       "17269                                 0                       0   \n",
       "8313                                  0                       0   \n",
       "9516                                  0                       0   \n",
       "1732                                  0                       0   \n",
       "\n",
       "       Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
       "4357                       0                    0                  0   \n",
       "17269                      0                    0                  0   \n",
       "8313                       0                    0                  0   \n",
       "9516                       0                    0                  0   \n",
       "1732                       0                    0                  0   \n",
       "\n",
       "       Studio_trenova  Studio_ufotable  \\\n",
       "4357                0                0   \n",
       "17269               0                0   \n",
       "8313                0                0   \n",
       "9516                0                0   \n",
       "1732                0                0   \n",
       "\n",
       "       Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
       "4357                                                   0                                          \n",
       "17269                                                  0                                          \n",
       "8313                                                   0                                          \n",
       "9516                                                   0                                          \n",
       "1732                                                   0                                          \n",
       "\n",
       "       Studio_ufotable, feel., Studio Flag  Release_Year  \n",
       "4357                                     0        2009.0  \n",
       "17269                                    0        2021.0  \n",
       "8313                                     0        2014.0  \n",
       "9516                                     0        2015.0  \n",
       "1732                                     0        2006.0  \n",
       "\n",
       "[5 rows x 1562 columns]"

      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.shape\n",
    "filtered_item_data_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e36921f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "5183"

      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df[\"Score\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "961b92d9",
   "metadata": {},
   "outputs": [
    {
     "data": {

      "image/png": "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",

      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(filtered_item_data_df['Score'].dropna(), bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f209fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function for the transformation\n",
    "def impute_score_column(filtered_item_data_df):\n",
    "    \"\"\"\n",
    "    Replaces 'UNKNOWN' with NaN in the 'Score' column and imputes missing values using the mean.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filtered_item_data_df : pandas.DataFrame\n",
    "        The DataFrame containing the 'Score' column to be processed.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The DataFrame with the 'Score' column imputed.\n",
    "    \"\"\"\n",
    "    # Replace 'UNKNOWN' with NaN\n",
    "    filtered_item_data_df['Score'] = filtered_item_data_df['Score'].replace('UNKNOWN', pd.NA)\n",
    "    \n",
    "    # Impute missing values with the mean\n",
    "    filtered_item_data_df['Score'] = filtered_item_data_df['Score'].astype(float).fillna(filtered_item_data_df['Score'].astype(float).mean())\n",
    "    \n",
    "    return filtered_item_data_df\n",
    "\n",
    "# Create the FunctionTransformer\n",
    "impute_score_transformer = FunctionTransformer(impute_score_column)\n",
    "\n",
    "# Apply the transformer\n",
    "filtered_item_data_df = impute_score_transformer.transform(filtered_item_data_df)\n",
    "\n",
    "# Verify that there are no missing values left in 'Score'\n",
    "print(filtered_item_data_df['Score'].isna().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03cacdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id                             Name             English name  \\\n",
      "0         1                     Cowboy Bebop             Cowboy Bebop   \n",
      "1         5  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie   \n",
      "2         6                           Trigun                   Trigun   \n",
      "3         7               Witch Hunter Robin       Witch Hunter Robin   \n",
      "4         8                   Bouken Ou Beet   Beet the Vandel Buster   \n",
      "\n",
      "                         Other name  Score  \\\n",
      "0                         カウボーイビバップ   8.75   \n",
      "1                    カウボーイビバップ 天国の扉   8.38   \n",
      "2                             トライガン   8.22   \n",
      "3  Witch Hunter ROBIN (ウイッチハンターロビン)   7.25   \n",
      "4                            冒険王ビィト   6.94   \n",
      "\n",
      "                                            Synopsis    Source  \\\n",
      "0  Crime is timeless. By the year 2071, humanity ...  Original   \n",
      "1  Another day, another bounty—such is the life o...  Original   \n",
      "2  Vash the Stampede is the man with a $$60,000,0...     Manga   \n",
      "3  Robin Sena is a powerful craft user drafted in...  Original   \n",
      "4  It is the dark century and the people are suff...     Manga   \n",
      "\n",
      "                           Rating  Rank  Popularity  ...  \\\n",
      "0  R - 17+ (violence & profanity)    41          43  ...   \n",
      "1  R - 17+ (violence & profanity)   189         602  ...   \n",
      "2       PG-13 - Teens 13 or older   328         246  ...   \n",
      "3       PG-13 - Teens 13 or older  2764        1795  ...   \n",
      "4                   PG - Children  4240        5126  ...   \n",
      "\n",
      "   Studio_pH Studio, D & D Pictures Studio_pH Studio, Noovo  \\\n",
      "0                                 0                       0   \n",
      "1                                 0                       0   \n",
      "2                                 0                       0   \n",
      "3                                 0                       0   \n",
      "4                                 0                       0   \n",
      "\n",
      "   Studio_production doA Studio_studio MOTHER  Studio_studio YOG  \\\n",
      "0                      0                    0                  0   \n",
      "1                      0                    0                  0   \n",
      "2                      0                    0                  0   \n",
      "3                      0                    0                  0   \n",
      "4                      0                    0                  0   \n",
      "\n",
      "   Studio_trenova  Studio_ufotable  \\\n",
      "0               0                0   \n",
      "1               0                0   \n",
      "2               0                0   \n",
      "3               0                0   \n",
      "4               0                0   \n",
      "\n",
      "   Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive  \\\n",
      "0                                                  0                                          \n",
      "1                                                  0                                          \n",
      "2                                                  0                                          \n",
      "3                                                  0                                          \n",
      "4                                                  0                                          \n",
      "\n",
      "   Studio_ufotable, feel., Studio Flag  Release_Year  \n",
      "0                                    0        1998.0  \n",
      "1                                    0        2001.0  \n",
      "2                                    0        1998.0  \n",
      "3                                    0        2002.0  \n",
      "4                                    0        2004.0  \n",
      "\n",
      "[5 rows x 1562 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "def filter_score_and_release_year(df):\n",
    "    \"\"\"\n",
    "    Filters rows where both 'Score' and 'Release_Year' are not null.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[df[\"Score\"].notna() & df[\"Release_Year\"].notna()]\n",
    "\n",
    "# Create the FunctionTransformer\n",
    "filter_transformer = FunctionTransformer(filter_score_and_release_year)\n",
    "\n",
    "# Apply the transformer to the filtered_item_data_df\n",
    "filtered_item_data_df = filter_transformer.transform(filtered_item_data_df)\n",
    "\n",
    "# Verify the result\n",
    "print(filtered_item_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8ed202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "anime_id                                                                                    0\n",
      "Name                                                                                        0\n",
      "English name                                                                                0\n",
      "Other name                                                                                  0\n",
      "Score                                                                                       0\n",
      "                                                                                           ..\n",
      "Studio_trenova                                                                              0\n",
      "Studio_ufotable                                                                             0\n",
      "Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive    0\n",
      "Studio_ufotable, feel., Studio Flag                                                         0\n",
      "Release_Year                                                                                0\n",
      "Length: 1562, dtype: int64\n"

     ]
    }
   ],
   "source": [
    "print(filtered_item_data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92e25c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(19848, 1562)"

      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7775449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Username', 'Mean Score', 'Completed', 'avg_Action',\n",
       "       'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
       "       'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
       "       'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
       "       'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
       "       'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
       "       'Age', 'Viewer_Category', 'Age_Group__Gen_Alpha', 'Age_Group__Zoomers',\n",
       "       'Age_Group__Millennials', 'Age_Group__Gen_X', 'Age_Group__Boomers_Plus',\n",
       "       'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
       "       'Category_Millennial_Favorites', 'Category_Retro_Anime_Lovers',\n",
       "       'Category_Zoomer_Picks', 'Gender_Female', 'Gender_Male',\n",
       "       'Gender_Non-Binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a73dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anime_id', 'Name', 'English name', 'Other name', 'Score', 'Synopsis',\n",

       "       'Source', 'Rating', 'Rank', 'Popularity',\n",
       "       ...\n",
       "       'Studio_pH Studio, D & D Pictures', 'Studio_pH Studio, Noovo',\n",
       "       'Studio_production doA', 'Studio_studio MOTHER', 'Studio_studio YOG',\n",
       "       'Studio_trenova', 'Studio_ufotable',\n",
       "       'Studio_ufotable, Shaft, A-1 Pictures, SILVER LINK., Lerche, Lay-duce, CloverWorks, Drive',\n",
       "       'Studio_ufotable, feel., Studio Flag', 'Release_Year'],\n",
       "      dtype='object', length=1562)"

      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5dfc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Username', 'Gender', 'Mean Score', 'Completed', 'Birth_Year',\n",
       "       'user_id', 'anime_id', 'Anime Title', 'rating', 'Genres',\n",
       "       'Genre_Action', 'Genre_Adventure', 'Genre_Avant Garde',\n",
       "       'Genre_Award Winning', 'Genre_Boys Love', 'Genre_Comedy', 'Genre_Drama',\n",
       "       'Genre_Ecchi', 'Genre_Erotica', 'Genre_Fantasy', 'Genre_Girls Love',\n",
       "       'Genre_Gourmet', 'Genre_Hentai', 'Genre_Horror', 'Genre_Mystery',\n",
       "       'Genre_Romance', 'Genre_Sci-Fi', 'Genre_Slice of Life', 'Genre_Sports',\n",
       "       'Genre_Supernatural', 'Genre_Suspense'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2284909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing 'UNKNOWN': ['English name', 'Other name', 'Rating', 'Scored By']\n"
     ]
    }
   ],
   "source": [
    "# Check if any column in filtered_item_data_df contains the value 'UNKNOWN'\n",
    "columns_with_unknown = filtered_item_data_df.columns[filtered_item_data_df.isin(['UNKNOWN']).any()]\n",
    "\n",
    "# Print the columns that contain 'UNKNOWN'\n",
    "print(\"Columns containing 'UNKNOWN':\", list(columns_with_unknown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e65f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances with 'UNKNOWN' values: 16965\n"
     ]
    }
   ],
   "source": [
    "unknown_counts = filtered_item_data_df.isin(['UNKNOWN']).sum().sum()\n",
    "print(f\"Total instances with 'UNKNOWN' values: {unknown_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3886534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_training_data(user_input_df, user_data_df, filtered_item_data_df):\n",
    "    \"\"\"\n",
    "    Prepares training data for a neural network using sparse matrices during processing,\n",
    "    then converts back to dense arrays in the output.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_input_df : DataFrame\n",
    "        Contains user ratings for anime with columns including user_id, anime_id, rating\n",
    "    user_data_df : DataFrame\n",
    "        Contains user demographic data and average genre ratings\n",
    "    filtered_item_data_df : DataFrame\n",
    "        Contains anime metadata including genres, types, and ratings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary containing:\n",
    "        - 'X_U': User features array (dense)\n",
    "        - 'X_A': Anime features array (dense)\n",
    "        - 'Y': Rating values array\n",
    "        - 'X_U_columns': List of column names for user features\n",
    "        - 'X_A_columns': List of column names for anime features\n",
    "        - 'Y_column': Name of the rating column\n",
    "        - 'X_U_indices': List of indices for user features\n",
    "        - 'X_A_indices': List of indices for anime features\n",
    "        - 'Y_index': Index of the rating column\n",
    "        - 'merged_df': The merged and cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Step 1: Merge dataframes with suffixes to handle column conflicts\n",
    "    merged_df = user_input_df.merge(user_data_df, on='user_id', suffixes=('', '_user'))\n",
    "    merged_df = merged_df.merge(filtered_item_data_df, on='anime_id', suffixes=('', '_anime'))\n",
    "    \n",
    "    # Step 2: Identify columns to drop (non-numerical or identifiers)\n",
    "    columns_to_drop = ['Username', 'user_id', 'anime_id', 'Anime Title', \n",
    "                     'Name', 'English name', 'Other name', 'Synopsis', \n",
    "                     'Source', \"Scored by\", 'Image URL']\n",
    "    \n",
    "    # Only drop columns that actually exist in the merged dataframe\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in merged_df.columns]\n",
    "    \n",
    "    # Drop identified columns\n",
    "    cleaned_df = merged_df.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Step 3: Define columns for each component\n",
    "    X_U_columns = [\n",
    "        'Mean Score', 'Completed',\n",
    "        'avg_Action', 'avg_Adventure', 'avg_Avant Garde', 'avg_Award Winning',\n",
    "        'avg_Boys Love', 'avg_Comedy', 'avg_Drama', 'avg_Ecchi', 'avg_Erotica',\n",
    "        'avg_Fantasy', 'avg_Girls Love', 'avg_Gourmet', 'avg_Hentai',\n",
    "        'avg_Horror', 'avg_Mystery', 'avg_Romance', 'avg_Sci-Fi',\n",
    "        'avg_Slice of Life', 'avg_Sports', 'avg_Supernatural', 'avg_Suspense',\n",
    "        'Gender_Female', 'Gender_Male', 'Gender_Non-Binary',\n",
    "        'Category_Classic_Era_Fans', 'Category_Gen_Alpha_Viewers',\n",
    "        'Category_Millennial_Favorites', \n",
    "        'Category_Retro_Anime_Lovers', \n",
    "        'Category_Zoomer_Picks'\n",
    "    ]\n",
    "    \n",
    "    excluded_columns = ['anime_id', 'Name', 'English name', 'Other name',\n",
    "                      'Score', \"Synopsis\", \"Source\", \"Rank\",\"Rating\"]\n",
    "    \n",
    "    X_A_columns = [col for col in filtered_item_data_df.columns \n",
    "                  if col not in excluded_columns and col in cleaned_df.columns]\n",
    "    X_U_columns = [col for col in X_U_columns if col in cleaned_df.columns]\n",
    "    \n",
    "    Y_column = \"rating\"\n",
    "    if Y_column not in cleaned_df.columns:\n",
    "        raise ValueError(f\"Rating column '{Y_column}' not found in merged dataframe\")\n",
    "    \n",
    "    # Step 4: Get indices for features\n",
    "    X_U_indices = [cleaned_df.columns.get_loc(col) for col in X_U_columns]\n",
    "    X_A_indices = [cleaned_df.columns.get_loc(col) for col in X_A_columns]\n",
    "    Y_index = cleaned_df.columns.get_loc(Y_column)\n",
    "    \n",
    "    # Step 5: Process with sparse matrices\n",
    "    # Convert relevant portions to sparse format\n",
    "    X_U_sparse = csr_matrix(cleaned_df.iloc[:, X_U_indices].values)\n",
    "    X_A_sparse = csr_matrix(cleaned_df.iloc[:, X_A_indices].values)\n",
    "    \n",
    "    # Perform sparse operations if needed (e.g., scaling)\n",
    "    # ... (your sparse-compatible preprocessing here) ...\n",
    "    \n",
    "    # Convert back to dense for output (if your model requires dense inputs)\n",
    "    X_U = X_U_sparse.toarray()\n",
    "    X_A = X_A_sparse.toarray()\n",
    "    Y = cleaned_df.iloc[:, Y_index].values\n",
    "    \n",
    "    return {\n",
    "        \"X_U\": X_U,\n",
    "        \"X_A\": X_A,\n",
    "        \"Y\": Y,\n",
    "        \"X_U_columns\": X_U_columns,\n",
    "        \"X_A_columns\": X_A_columns,\n",
    "        \"Y_column\": Y_column,\n",
    "        \"X_U_indices\": X_U_indices,\n",
    "        \"X_A_indices\": X_A_indices,\n",
    "        \"Y_index\": Y_index,\n",
    "        \"merged_df\": cleaned_df,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "486c4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "# Select a smaller dataframe with 200000 samples from user_input\n",
    "user_input_sample = user_input.sample(n=200000, random_state=42)\n",
    "\n",
    "# Ensure all columns in user_input_sample, user_data, and filtered_item_data_df are numeric\n",
    "user_input_sample = user_input_sample.select_dtypes(include=[np.number])\n",
    "user_data = user_data.select_dtypes(include=[np.number])\n",
    "filtered_item_data_df = filtered_item_data_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Prepare the training data using the sampled dataframe\n",
    "result = prepare_training_data(user_input_sample, user_data, filtered_item_data_df)\n",
    "\n",
    "# Access the prepared data\n",
    "X_U = result['X_U']  # User features\n",
    "X_A = result['X_A']  # Anime features\n",
    "Y = result['Y']      # Ratings\n",
    "\n",
    "# You can also access indices if needed\n",
    "X_U_indices = result['X_U_indices']\n",
    "X_A_indices = result['X_A_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed29ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(200000, 31)"

      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ead081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(200000, 1551)"

      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dad9a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "(200000,)"

      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8bb3363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "array([ 7,  9, 10,  9, 10,  7,  9,  2,  8,  8], dtype=int64)"

      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d561d94",
   "metadata": {},
   "source": [
    "# Neural Network for implementing Content Based Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30fd1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c72040",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Training set: 120000 samples\n",
      "Validation set: 40000 samples\n",
      "Test set: 40000 samples\n"

     ]
    }
   ],
>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# --- Scaling the data ---\n",
    "# Create scalers\n",
    "user_scaler = StandardScaler()\n",
    "anime_scaler = StandardScaler()\n",
    "\n",
    "# Ensure all columns in X_A are numeric\n",
    "# Convert categorical columns (e.g., 'Rating') to numeric using one-hot encoding\n",
    "#X_A_df = pd.DataFrame(X_A, columns=result['X_A_columns'])  # Convert X_A to DataFrame for easier processing\n",
    "\n",
    "# print(X_A_df.columns)  # Check the columns after encoding\n",
    "# Scale the features\n",
    "X_U_scaled = user_scaler.fit_transform(X_U)\n",
    "X_A_scaled = anime_scaler.fit_transform(X_A)\n",
    "\n",
    "# --- Splitting the scaled data ---\n",
    "# First split: 80% train+val, 20% test\n",
    "X_U_temp, X_U_test, X_A_temp, X_A_test, Y_temp, Y_test = train_test_split(\n",
    "    X_U_scaled, X_A_scaled, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 75% train, 25% validation (results in 60% train, 20% val, 20% test overall)\n",
    "X_U_train, X_U_val, X_A_train, X_A_val, Y_train, Y_val = train_test_split(\n",
    "    X_U_temp, X_A_temp, Y_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_U_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_U_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_U_test.shape[0]} samples\")\n",
    "\n",
    "print(X_U_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======

   "execution_count": 46,

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
   "id": "507e6f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",

       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1551</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",

       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_nn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,936</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",

       "│ item_nn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">442,336</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",

       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_nn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ item_nn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",

       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1551\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",

       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_nn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m51,936\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",

       "│ item_nn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │    \u001b[38;5;34m442,336\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",

       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_nn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ item_nn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [

       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,552</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m495,552\u001b[0m (1.89 MB)\n"

      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [

       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">493,760</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m493,760\u001b[0m (1.88 MB)\n"

      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
<<<<<<< HEAD
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 26.2260 - mean_absolute_error: 3.3742 - val_loss: 2.0456 - val_mean_absolute_error: 1.0894 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m 410/3750\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.1565 - mean_absolute_error: 1.1314"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_U_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_A_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_U_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_A_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     78\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
=======

      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 25.8050 - mean_absolute_error: 3.3121 - val_loss: 2.1218 - val_mean_absolute_error: 1.0890 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.1539 - mean_absolute_error: 1.1267 - val_loss: 2.0461 - val_mean_absolute_error: 1.0746 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 2.0223 - mean_absolute_error: 1.0895 - val_loss: 1.8931 - val_mean_absolute_error: 1.0346 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 1.9313 - mean_absolute_error: 1.0635 - val_loss: 2.0145 - val_mean_absolute_error: 1.0475 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 1.8478 - mean_absolute_error: 1.0403 - val_loss: 1.9820 - val_mean_absolute_error: 1.0413 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.7952 - mean_absolute_error: 1.0250 - val_loss: 1.8815 - val_mean_absolute_error: 1.0239 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.7410 - mean_absolute_error: 1.0105 - val_loss: 1.8926 - val_mean_absolute_error: 1.0244 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.6892 - mean_absolute_error: 0.9946 - val_loss: 1.9020 - val_mean_absolute_error: 1.0305 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.6419 - mean_absolute_error: 0.9811 - val_loss: 1.8870 - val_mean_absolute_error: 1.0257 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.5605 - mean_absolute_error: 0.9550 - val_loss: 1.8100 - val_mean_absolute_error: 1.0130 - learning_rate: 2.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.5065 - mean_absolute_error: 0.9396 - val_loss: 1.8278 - val_mean_absolute_error: 1.0157 - learning_rate: 2.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4746 - mean_absolute_error: 0.9288 - val_loss: 1.8416 - val_mean_absolute_error: 1.0190 - learning_rate: 2.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4438 - mean_absolute_error: 0.9205 - val_loss: 1.8578 - val_mean_absolute_error: 1.0230 - learning_rate: 2.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4202 - mean_absolute_error: 0.9142 - val_loss: 1.8672 - val_mean_absolute_error: 1.0248 - learning_rate: 4.0000e-05\n",
      "Epoch 15/60\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4207 - mean_absolute_error: 0.9130 - val_loss: 1.8752 - val_mean_absolute_error: 1.0260 - learning_rate: 4.0000e-05\n"

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
     ]
    }
   ],
   "source": [
    "# --- TensorFlow model ---\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define inputs for user and item features\n",
    "user_input = tf.keras.Input(shape=(X_U_train.shape[1],), name=\"user_input\")\n",
    "item_input = tf.keras.Input(shape=(X_A_train.shape[1],), name=\"item_input\")\n",
    "\n",
    "# Define user network with dropout for regularization\n",
    "user_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='linear')\n",
    "], name=\"user_nn\")\n",
    "\n",
    "# Define item network with dropout for regularization\n",
    "item_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='linear')\n",
    "], name=\"item_nn\")\n",
    "\n",
    "# Pass inputs through respective networks\n",
    "vu = user_nn(user_input)\n",
    "va = item_nn(item_input)\n",
    "\n",
    "# Compute dot product\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, va])\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.Model([user_input, item_input], output)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_U_train, X_A_train],\n",
    "    Y_train,\n",
    "    validation_data=([X_U_val, X_A_val], Y_val),\n",
    "    epochs=60,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======

   "execution_count": 47,

>>>>>>> 8cb9104450c6bcd59b623b3f26d08159d2a3db21
   "id": "5459029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - loss: 1.8247 - mean_absolute_error: 1.0186\n",
      "Test loss (MSE): 1.830672025680542\n",
      "Test MAE: 1.0208982229232788\n"

     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = model.evaluate([X_U_test, X_A_test], Y_test, verbose=1)\n",
    "print(f\"Test loss (MSE): {test_results[0]}\")\n",
    "print(f\"Test MAE: {test_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "419ad13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/recommender_model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/recommender_model_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_model/recommender_model_5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 26), dtype=tf.float32, name='user_input'), TensorSpec(shape=(None, 39), dtype=tf.float32, name='item_input')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2635126906064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126903952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126904144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126902992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126904336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126903568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126904720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126901840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126900880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126905104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126901456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126901648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126902608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126899536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324311312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324308624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324311504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324310928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324309968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324309776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635126903760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636038710928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324308816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421656080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636038711504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2634324311888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421658000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421658768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421657616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421657232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421658384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421660304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421659920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635129258448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635129259024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421659152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2636421656272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635129259984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2635129260560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save in TensorFlow SavedModel format\n",
    "model.export('../saved_model/recommender_model_5')\n",
    "\n",
    "# Save in HDF5 format\n",
    "model.save('../saved_model/recommender_model_5.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec9301f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save in TensorFlow SavedModel format\n",
    "# model.export('../saved_model/recommender_model_2')\n",
    "\n",
    "# # Save in HDF5 format\n",
    "# model.save('../recommender_model_2.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "b724a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('../saved_model/recommender_model_5.h5')\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "a0ca098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98965188, -0.22051907, -0.38007022, -0.43310719,  0.1133751 ,\n",
       "        -0.0939215 ,  0.1675034 , -1.05901591, -0.27850162, -1.29044085,\n",
       "        -2.18552196, -0.3773842 , -1.89376243, -1.4985865 , -0.69818678,\n",
       "        -0.33805474,  0.19274676, -0.59244886, -0.70618884, -0.91375968,\n",
       "        -3.24719741, -0.05151517,  0.47097244, -0.64025301,  0.64588565,\n",
       "        -0.0603226 ],\n",
       "       [-0.58496404, -0.42199343, -0.77083646, -0.46852991,  0.13738286,\n",
       "        -0.11975497,  0.1675034 , -0.48695055, -0.91781178, -0.24309694,\n",
       "         0.0742905 , -0.24854784,  0.11341228, -1.15883208,  0.09474619,\n",
       "        -0.94629719, -0.72719851, -0.36796787, -0.56181687, -0.54637608,\n",
       "         0.21853859, -0.84524904, -0.48072108, -0.64025301,  0.64588565,\n",
       "        -0.0603226 ],\n",
       "       [-1.59668364,  0.66336846, -1.83323218, -1.4603659 , -0.32676706,\n",
       "        -1.01100951, -0.70651971, -1.46422888, -1.5179805 , -1.37919881,\n",
       "         0.0742905 , -1.43149982, -0.87691181, -1.24119679,  0.09474619,\n",
       "        -1.55453964, -1.5139938 , -1.66759467, -1.42804868, -0.77730291,\n",
       "        -1.11654704, -2.01753291, -1.67307272, -0.64025301,  0.64588565,\n",
       "        -0.0603226 ],\n",
       "       [-1.98872499,  0.33840981, -1.0516997 , -1.55482647,  0.22541129,\n",
       "        -2.677268  , -0.70651971, -1.21395028, -2.40518643, -0.5537498 ,\n",
       "         0.0742905 , -1.86485847, -1.45165347,  0.56053123, -0.87723616,\n",
       "        -0.74687343, -1.5139938 , -2.10474186, -1.10321175, -0.65134282,\n",
       "        -1.41831297, -1.2726442 , -2.46068115, -0.64025301,  0.64588565,\n",
       "        -0.0603226 ],\n",
       "       [ 1.34994971, -0.77078239,  1.45164654,  1.46791179,  0.13738286,\n",
       "         1.28816888,  0.1675034 ,  1.38417989,  1.37848594,  1.7894603 ,\n",
       "         0.0742905 ,  1.21550164,  0.11341228,  0.09722974,  0.09474619,\n",
       "         1.24736411,  1.27005109,  0.75443709,  1.32704969,  0.84968161,\n",
       "         0.41057146,  1.38941709, -0.7104402 ,  1.56188253, -1.54826167,\n",
       "        -0.0603226 ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_U_test[:5]\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "b345239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65562593, -0.36139309, -0.61492479, -0.87186362, -0.58855008,\n",
       "        -0.11829435, -0.29748685, -0.11009191,  1.23694159, -0.65355018,\n",
       "        -0.32889138, -0.05656456, -0.63779374, -0.1043251 , -0.07535655,\n",
       "        -0.12748236, -0.24508024, -0.34516694, -0.64304102, -0.55899749,\n",
       "        -0.22349669, -0.16714966, -0.4601306 , -0.21371213, -0.07282469,\n",
       "        -0.41755222, -0.06413937, -0.12460821,  2.73185176, -0.26775345,\n",
       "        -1.35410172,  0.        , -0.20635892, -0.18403974, -1.16611204,\n",
       "         1.88005579, -0.35801571, -0.12727908,  0.42531758],\n",
       "       [-0.14231978, -0.34695551, -0.47672977,  1.14696838,  1.69909076,\n",
       "        -0.11829435, -0.29748685, -0.11009191, -0.80844561, -0.65355018,\n",
       "        -0.32889138, -0.05656456,  1.56790501, -0.1043251 , -0.07535655,\n",
       "        -0.12748236, -0.24508024, -0.34516694, -0.64304102, -0.55899749,\n",
       "        -0.22349669, -0.16714966, -0.4601306 , -0.21371213, -0.07282469,\n",
       "        -0.41755222, -0.06413937, -0.12460821,  2.73185176, -0.26775345,\n",
       "        -1.35410172,  0.        , -0.20635892, -0.18403974,  0.85755053,\n",
       "        -0.53189911, -0.35801571, -0.12727908, -0.54368631],\n",
       "       [ 2.24083924, -0.36235027, -0.66684129,  1.14696838,  1.69909076,\n",
       "        -0.11829435, -0.29748685, -0.11009191,  1.23694159,  1.53010439,\n",
       "        -0.32889138, -0.05656456, -0.63779374, -0.1043251 , -0.07535655,\n",
       "        -0.12748236, -0.24508024, -0.34516694,  1.55511075,  1.78891679,\n",
       "        -0.22349669, -0.16714966, -0.4601306 , -0.21371213, -0.07282469,\n",
       "         2.39491005, -0.06413937, -0.12460821, -0.36605207, -0.26775345,\n",
       "        -1.35410172,  0.        , -0.20635892, -0.18403974,  0.85755053,\n",
       "        -0.53189911, -0.35801571, -0.12727908, -2.89698147],\n",
       "       [ 1.96417923, -0.36143297, -0.66347679, -0.87186362, -0.58855008,\n",
       "        -0.11829435, -0.29748685, -0.11009191, -0.80844561, -0.65355018,\n",
       "        -0.32889138, -0.05656456, -0.63779374, -0.1043251 , -0.07535655,\n",
       "        -0.12748236, -0.24508024, -0.34516694, -0.64304102, -0.55899749,\n",
       "         4.47433919, -0.16714966, -0.4601306 , -0.21371213, -0.07282469,\n",
       "        -0.41755222, -0.06413937, -0.12460821,  2.73185176, -0.26775345,\n",
       "        -1.35410172,  0.        , -0.20635892, -0.18403974,  0.85755053,\n",
       "        -0.53189911, -0.35801571, -0.12727908, -2.0664067 ],\n",
       "       [-0.95385581,  6.17184826,  5.53505563,  1.14696838, -0.58855008,\n",
       "        -0.11829435,  3.36149313, -0.11009191, -0.80844561,  1.53010439,\n",
       "        -0.32889138, -0.05656456, -0.63779374, -0.1043251 , -0.07535655,\n",
       "        -0.12748236, -0.24508024, -0.34516694, -0.64304102, -0.55899749,\n",
       "        -0.22349669, -0.16714966, -0.4601306 ,  4.67919155, -0.07282469,\n",
       "        -0.41755222, -0.06413937, -0.12460821, -0.36605207, -0.26775345,\n",
       "         0.73849696,  0.        , -0.20635892, -0.18403974, -1.16611204,\n",
       "         1.88005579, -0.35801571, -0.12727908,  0.97903409]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_A_test[:5]"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "a41b7802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.2718883],\n",
       "       [7.962675 ],\n",
       "       [6.3944054],\n",
       "       [5.7783704],\n",
       "       [9.027118 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions on X-U_test and X-A_test\n",
    "predictions = model.predict([X_U_test[:20], X_A_test[:20]])\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "id": "128f511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  8,  6,  8, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b28c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(12, 4))\\nplt.subplot(1, 2, 1)\\nplt.plot(history.history['loss'], label='Training Loss')\\nplt.plot(history.history['val_loss'], label='Validation Loss')\\nplt.title('Loss Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('Loss (MSE)')\\nplt.legend()\\n\\nplt.subplot(1, 2, 2)\\nplt.plot(history.history['mean_absolute_error'], label='Training MAE')\\nplt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\\nplt.title('Mean Absolute Error Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('MAE')\\nplt.legend()\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Plot training history\n",
    "# Uncomment if you're running in an environment that supports plotting\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "plt.title('Mean Absolute Error Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
